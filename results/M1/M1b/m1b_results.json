{
  "name": "M1b",
  "description": "Adam optimizer (adaptive learning rates) and early stopping, patience = 5",
  "config": {
    "hidden_layers": [
      128,
      64
    ],
    "dropout_rate": 0.0,
    "optimizer": "<class 'neural_net.optimizers.adam.Adam'>",
    "learning_rate": 0.001,
    "momentum": 0.0,
    "batch_size": 512,
    "epochs": 50,
    "use_l2": false,
    "l2_lambda": 0.0,
    "early_stopping": true
  },
  "test_metrics": null,
  "train_time_seconds": 140.36711168289185,
  "epochs_completed": 29,
  "timestamp": "2025-10-30 17:08:56"
}